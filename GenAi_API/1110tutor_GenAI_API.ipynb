{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iel3-lQX6bZv"
      },
      "source": [
        "# 2024/11/10 Tutor : GenAI API ‰ΩøÁî®ÊïôÂ≠∏ -- Âø´ÈÄüÊê≠Âª∫Ëá™Â∑±ÁöÑÊáâÁî®\n",
        "\n",
        "ÈÄô‰ªΩ‰ΩúÊ•≠Ë¶ÅÊ±ÇÊàëÂÄë‰ΩøGenminiÊâÆÊºîÊàê‰∏Ä‰ΩçÂøÉÁêÜË´ÆÂïÜÂ∏´ÔºåÊ†πÊìöÁâπÂÆöÁöÑÊ†ºÂºèÂõûÁ≠îÊåáÂÆöÁöÑÂïèÈ°å„ÄÇ\n",
        "\n",
        "ÊàëÂÖàÁî®chatgptÊää‰ΩúÊ•≠Ë¶ÅÊ±ÇÁîüÊàê‰∫Üchatbot_task Âíåprompt_for_task„ÄÇÂØ¶Èöõ‰ΩøÁî®ÂæåÂçªÁôºÁèæGenminiÂñúÊ≠°ÊääËá™Â∑±ÊÄùËÄÉÁöÑÈÅéÁ®ã‰πüÂØ´Âá∫‰æÜÔºåËß£ÈáãÁÇ∫‰ªÄÈ∫ºË¶ÅË™™ÊØèÂè•Ë©±„ÄÇÊñºÊòØÊàëÁâπÂà•Ë¶ÅÂÆÉÂÅáË£ùËá™Â∑±Âú®ËÅäÂ§©‰ª•Á≤æÁ∞°ÊñáÂ≠óÂÖßÂÆπ„ÄÇÂÆÉÁÑ°Ê≥ïÊääÁ¢∫Ë™ç‰ΩïËÄÖÊòØËÄÅÂ∏´emojiÔºåÈõñÁÑ∂‰ΩçÁΩÆÊ≠£Á¢∫ÔºåÂçªÂ∏∏Â∏∏Âá∫ÁèæÊõ∏Êú¨ÊàñËä±Á≠â‰∏çÁõ∏Âπ≤ÁöÑÁ¨¶Ëôü„ÄÇÊâÄ‰ª•ÊàëÁõ¥Êé•Áµ¶‰∫à‰ªñÊ≠£Á¢∫ÁöÑÁ¨¶Ëôü‰ΩøÁî®„ÄÇÁ∂ìÈÅéÊ∏¨Ë©¶ÂæåÁ¢∫Ë™çÂÆÉÂèØ‰ª•Ê≠£Â∏∏ÂõûÁ≠îÂïèÈ°å\n",
        "\n",
        "‰ª•‰∏ãÊòØÊàëË™øÊï¥ÈÅéÂæå‰ΩøÁî®ÁöÑpromt\n",
        "\n",
        "chatbot_task = \"‰Ω†ÊòØ‰∏ÄÂêçÂ∞àÊ•≠ÁöÑÂøÉÁêÜË´ÆÂïÜÂ∏´ÔºåÁèæÂú®ÊàëÊúâ‰∏Ä‰∫õÂõ∞ÊìæÔºåË´ã‰Ω†‰ª•ÂøÉÁêÜË´ÆÂïÜÂ∏´ÁöÑË∫´‰ªΩÂõûÁ≠îÊàë‰∏ÄÊï¥ÊÆµË©±ÔºåÂÉèÊòØÂú®ÂíåÊàëËÅäÂ§©‰∏ÄÊ®£Ôºå‰∏¶‰∏î‰∏çÁî®Êää‰Ω†ÊÄùËÄÉÁöÑÂÖßÂÆπÈ°ØÁ§∫Âá∫‰æÜ\"\n",
        "\n",
        "prompt_for_task = \"Ë´ã‰Ω†Ê†πÊìö‰ª•‰∏äË®≠ÂÆöÔºåÊâÆÊºîÂøÉÁêÜË´ÆÂïÜÂ∏´Ôºå‰∏¶ÊåâÁÖßÊ†ºÂºèË¶ÅÊ±ÇÂõûÁ≠îÔºå‰∏¶Á¢∫‰øùÂõûÊáâÁ¨¶Âêà‰ª•‰∏ã‰∏âÈ†ÖË¶ÅÊ±ÇÔºö1. ÂõûÁ≠îÂøÖÈ†àÊòØÂÆåÂÖ®ÁπÅÈ´î‰∏≠Êñá„ÄÇ2. ÂõûÁ≠îÁöÑÈñãÈ†≠ÂøÖÈ†àÈôÑ‰∏ä‰∏ÄÂÄãÁâπÂÆöÁöÑËÄÅÂ∏´ emojiÁ¨¶Ëôüüë©‚Äçüè´Ôºå‰∏î emoji ÁöÑ‰ΩçÁΩÆÂõ∫ÂÆöÂú®ÊúÄÈñãÈ†≠Ôºå‰∏çËÉΩÂ§öÊàñÂ∞ë„ÄÇ3. ÊØèÊ¨°ÂõûÁ≠îÁöÑÂ≠óÊï∏‰∏çÂèØ‰ª•Ë∂ÖÈÅé200 ÂÄã‰∏≠ÊñáÂ≠ó„ÄÇ\"\n",
        "\n",
        "\n",
        "1. ÂÖàÈªûÈÅ∏ Ê™îÊ°à --> Âú®Èõ≤Á´ØÁ°¨Á¢ü‰∏≠ÂÑ≤Â≠òÂâØÊú¨\n",
        "2. Á≠âÂæÖÂâØÊú¨È†ÅÈù¢Ë∑≥Âá∫\n",
        "3. Âà∞Èõ≤Á´ØÁ°¨Á¢ü‰∏äÁ¢∫Ë™çÊúâÂ≠òÂ•ΩÂâØÊú¨(ÈªòË™çÊúÉÂú®Èõ≤Á´ØÁ°¨Á¢üÂâµÂª∫‰∏ÄÂÄãÂêçÁÇ∫ Colab NoterbooksÁöÑË≥áÊñôÂ§æÔºå‰∏¶Âú®ÂÖ∂‰∏≠Êñ∞Â¢û‰∏ÄÂÄã .ipynb Ê™îÊ°à)ÔºåÁ¢∫Ë™çÂæåÁïôËëóÈõ≤Á´ØÁ°¨Á¢üÈ†ÅÈù¢ÔºåÂõûÂà∞ colab ÂâØÊú¨È†ÅÈù¢\n",
        "4. ÈªûÈÅ∏Âè≥‰∏äËßíÁöÑÈÄ£Á∑öÔºåÂõ†ÁÇ∫‰∏çÈúÄË¶ÅË∑ëÂ§ßÊ®°Âûã,‰ΩøÁî® API\n",
        "5. ÂÆåÊàê‰∫ÜÔºåÂèØ‰ª•ÁπºÁ∫å‰∏ã‰∏ÄÊ≠•\n",
        "\n",
        "Objective:\n",
        "- Understand how to build your own Language Model Application by calling API and feeding prompts.\n",
        "\n",
        "In this project, you only need to choose **ONE** API.\n",
        "- **Gemini**: Free but slower.\n",
        "- **Other Choices ?**: Coming soon ~~\n",
        "\n",
        "**Start:**\n",
        "Hit one of these two buttons to unfold the blcoks.\n",
        "\n",
        "**Remember**, if you decide to use gemini. You should only execute the code blocks under **\"Gemini API\"**, and no need to execute the code blocks under Other Choices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryzCrCD6Sn5U"
      },
      "source": [
        "# Gemini API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGNPORMFfGei"
      },
      "source": [
        "## Part 0: Install, Import and Setup\n",
        "**Remember to fill in your GOOGLE_API_KEY in this block, the tutorial to get the API is in 2024/11/10 slide ppt.**\n",
        "\n",
        "Please make sure not to share your API with anyone else."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V9VXIQacd5ZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14503a7a-a35d-4d5e-ccb7-cd38fb82eb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.3 (from gradio)\n",
            "  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.3->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.3->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.6.0-py3-none-any.whl (57.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.6.0 gradio-client-1.4.3 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.4 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n",
            "Set Gemini API sucessfully!!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip3 install gradio\n",
        "!pip install -q -U google-generativeai\n",
        "\n",
        "# Import packages\n",
        "import google.generativeai as genai\n",
        "from typing import List, Tuple\n",
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "# Set up Gemini API key\n",
        "## TODO: Fill in your Gemini API in the \"\"\n",
        "#GOOGLE_API_KEY=\"AIzaSyBovp96uPJRH_cMWpiEzxzaXau8Yi-anYQ\"\n",
        "GOOGLE_API_KEY=\"AIzaSyDYPadibrUkCQx9sI9o3qoPUXfKyz3gCbE\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "# Check if you have set your Gemini API successfully\n",
        "# You should see \"Set Gemini API sucessfully!!\" if nothing goes wrong.\n",
        "try:\n",
        "    model.generate_content(\n",
        "      \"test\",\n",
        "    )\n",
        "    print(\"Set Gemini API sucessfully!!\")\n",
        "except:\n",
        "    print(\"There seems to be something wrong with your Gemini API. Please follow our demonstration in the slide to get a correct one.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifCr17v4d12K"
      },
      "source": [
        "## Part 1: Summarization\n",
        "\n",
        "In this task, you are asked to prompt your chatbot into a **summarizer.** Its job is when the user inputs an article, it can summarize the article for the user.\n",
        "\n",
        "You need to:\n",
        "1. Come up with a prompt for summarization and fill it in **prompt_for_summarization**.\n",
        "2. **Hit the run button![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==). (The run button will turn into this state![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) when sucessfully executed.)** An interface wiill pop up.\n",
        "3. Find an article on your own or use our example article, and fill it in the block named \"Article\".\n",
        "4. Hit the \"Send\" button to produce the summarization. (You can use the \"Temperature\" slide to control the creativeness of the output.)\n",
        "5. If you **want to change your prompt**, hit the run button again to stop the cell. Then go back to step 1.\n",
        "6. After you get the desired result, hit the button \"Export\" to save your result. There will be a file named part1.json appears in the file list. **Remember to download it to your own computer if you need.**\n",
        "\n",
        "Note:\n",
        "\n",
        "*  If you hit the \"Export\" button again, the previous result will be covered, so make sure to download it first.\n",
        "*  prompt example: \"Please summerize the following article in detail and in depth in 500 words, you have to incorporate specific details about the individuals' backgrounds and their daily lives. To enhance the summary, please incorporate direct references to the original text.\"\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Before you run this cell, make sure you have run Part 0 before.\n",
        "\n",
        "**Remember to stop this cell before you go on to the next one.**\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) means the cell is  running, ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==) means the cell is idle."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4AL3SR3G8jDZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbAzA7K5SuBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "b069a8a5-b468-4831-a425-dd3447f10dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://80b559149ea475de39.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://80b559149ea475de39.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://80b559149ea475de39.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "## TODO: Input the prompt in the \"\"\n",
        "prompt_for_summarization = \"ÁÇ∫Êî∂Âà∞ÁöÑÊñá‰ª∂ÁîüÊàê100Â≠óÁöÑÊëòË¶ÅÔºå‰∏≠ÊñáÂíåËã±ÊñáÁöÑÁâàÊú¨Ôºå‰∏¶Âú®Ëº∏Âá∫ÁµêÂ∞æÂä†ÂÖ•‰∫îÂÄãemoji\"\n",
        "# function to clear the conversation\n",
        "def reset() -> List:\n",
        "    return []\n",
        "\n",
        "# function to call the model to generate\n",
        "def interact_summarization(prompt: str, article: str, temp = 1.0) -> List[Tuple[str, str]]:\n",
        "    '''\n",
        "      * Arguments\n",
        "\n",
        "        - prompt: the prompt that we use in this section\n",
        "\n",
        "        - article: the article to be summarized\n",
        "\n",
        "        - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
        "                The higher the temperature is, the more creative response you will get.\n",
        "    '''\n",
        "    input = f\"{prompt}\\n{article}\"\n",
        "    response = model.generate_content(\n",
        "      input,\n",
        "      generation_config=genai.types.GenerationConfig(temperature=temp),\n",
        "      safety_settings=[\n",
        "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          ]\n",
        "    )\n",
        "\n",
        "    return [(input, response.text)]\n",
        "\n",
        "# function to export the whole conversation log\n",
        "def export_summarization(chatbot: List[Tuple[str, str]], article: str) -> None:\n",
        "    '''\n",
        "    * Arguments\n",
        "\n",
        "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
        "\n",
        "      - article: the article to be summarized\n",
        "\n",
        "    '''\n",
        "    target = {\"chatbot\": chatbot, \"article\": article}\n",
        "    with open(\"part1.json\", \"w\") as file:\n",
        "        json.dump(target, file)\n",
        "\n",
        "\n",
        "# This part constructs the Gradio UI interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Part1: Summarization\\nFill in any article you like and let the chatbot summarize it for you!!\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    prompt_textbox = gr.Textbox(label=\"Prompt\", value=prompt_for_summarization, visible=False)\n",
        "    # You can replace the article in variable \"value\" to get the summerization\n",
        "    article_textbox = gr.Textbox(label=\"Article\", interactive = True, value = \"With house prices soaring, it's not easy finding somewhere to live. And this community has thrown in the towel. Meet Seattle's rolling neighborhood of RVs, where each unassuming vehicle is a capsule home. The unusual format has been captured in a series of photographs by visual journalist Anna Erickson. Meet Bud Dodson, 57, and welcome to his home: An RV in Seattle's SoDo where he watches over the parking lot in exchange for a spot . No place like home: John Warden, 52, has turned his $200 vehicle into his home after his apartment burned down years ago . There are around 30 drivers that float in and out of this parking lot in the SoDo (South of Downtown) area of the city in Washington State. One might not notice them in the mornings as hundreds of workers in the nearby factories, such as Starbucks, park up and rush into work. But on the weekends, as the rabble flocks back to their beds, this unique group remains. John Worden, 52, has been living in his vehicle for years since his apartment burned down and he was left homeless. He told Anna his car cost $200, and doesn't drive very well. But for a home, it's just about enough. Though plan on the outside, it is a Pandora's Box inside, Anna tells DailyMail.com. 'It was scattered with trinkets that he had been collecting over the years,' she explained, 'and a pile of beer cans that he was saving to turn in for money.' For work, he panhandles while helping people find parking spaces at Safeco Field stadium, where he used to be a cook. People come and go for work in the factories nearby, but on the weekend it is just the RV-dwellers that area left . Daily life: Here Bud can be seen preparing himself a barbecue on the gravel outside his capsule home, one of about 30 in the community . Eclectic: While Bud's RV is organized and functional, John's is full of trinkets and belongings dating back years . Alongside him - most of the time - is Bud Dodson, 57. While some are forced to move about regularly, Dodson, a maintenance man, looks after the parking lot in exchange for a semi-permanent spot. His home has its own unique stamp on it. 'He had really made the RV his home and taken good care of it,' Anna described. 'It was more functional [than John's] and a cleaner space with a bed, kitchen and bathroom.' Whether organized or eclectic, however, each one is home. 'None of them seem to want to move on,' Anna said. 'It's not perfect but they seem pretty content. Move in, move out: Some have agreements to stay, but others have to keep driving around to find a spot . John works as a panhandler at Safeco Fields stadium, where he used to work as a cook . He is content with his life in between the usual confines of society . Personal: To many this may just seem like a parking lot but for these men it is a very personal space . 'Bud is very grateful, he said the parking lot owner is just such a nice guy to let him live like this.' She came across them when she stopped to ask a seemingly homeless man for directions. 'We got talking,' she said, 'and he mentioned that he lived nearby in an RV. I went round to look and there was a whole bunch of them.' Curious, she spent about two months returning to the spot, meeting with the community and building their trust. 'These RVs are their homes so it's a very personal thing,' she explained.\")\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Temperature\\n Temperature is used to control the output of the chatbot. The higher the temperature is, the more creative response you will get.\")\n",
        "        temperature_slider = gr.Slider(0.0, 1.0, 0.7, step = 0.1, label=\"Temperature\")\n",
        "    with gr.Row():\n",
        "        sent_button = gr.Button(value=\"Send\")\n",
        "        reset_button = gr.Button(value=\"Reset\")\n",
        "\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Save your Result.\\n After you get a satisfied result. Click the export button to recode it.\")\n",
        "        export_button = gr.Button(value=\"Export\")\n",
        "    sent_button.click(interact_summarization, inputs=[prompt_textbox, article_textbox, temperature_slider], outputs=[chatbot])\n",
        "    reset_button.click(reset, outputs=[chatbot])\n",
        "    export_button.click(export_summarization, inputs=[chatbot, article_textbox])\n",
        "\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdUFavirf5Bj"
      },
      "source": [
        "## Part 2: Role-Play\n",
        "In this task, you are asked to prompt your chatbot into **playing a roleplaying game**. You should assign it a character, then prompt it into that character.\n",
        "\n",
        "You need to:\n",
        "1. Come up with a **character** you want the chatbot to act and the prompt to make the chatbot into that character. Fill the character in **character_for_chatbot**, and fill the prompt in **prompt_for_roleplay**.\n",
        "2. **Hit the run button![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==). (The run button will turn into this state![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) when sucessfully executed.)** It will pop up an interface.\n",
        "3. Interact with the chatbot for **2 rounds**. Type what you want to say in the block \"Input\", then hit the button \"Send\". (You can use the \"Temperature\" slide to control the creativeness of the output.)\n",
        "4. If you **want to change your prompt or the character**, hit the run button again to stop the cell. Then go back to step 1.\n",
        "5. After you get the desired result, hit the button \"Export\" to save your result. There will be a file named part2.json appears in the file list. **Remember to download it to your own computer if you need.**\n",
        "\n",
        "Note:\n",
        "\n",
        "\n",
        "*  If you hit the \"Export\" button again, the previous result will be covered, so make sure to download it first.\n",
        "*  character example: \"Chinese chatbot\"\n",
        "*  prompt example: \"Tell me what you can do and have a chat with me in Traditional Chinese.\"\n",
        "---\n",
        "\n",
        "\n",
        "Before you run this cell, make sure you have run Part 0.\n",
        "\n",
        "**Remember to stop this cell before you go on to the next one.**\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) means the cell is  running, ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==) means the cell is idle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH_QN45qf4bK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "01be324d-3ea4-4def-9637-93bd40b4965c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://342ae9b0bb183ae791.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://342ae9b0bb183ae791.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://342ae9b0bb183ae791.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: Fill in the below two lines: character_for_chatbot and prompt_for_roleplay\n",
        "# The first one is the character you want your chatbot to play\n",
        "# The second one is the prompt to make the chatbot be a certain character\n",
        "character_for_chatbot = \"my boyfriend\"\n",
        "prompt_for_roleplay = \"chat with me,each santence should add emoji in the end\"\n",
        "\n",
        "# function to clear the coversation\n",
        "def reset() -> List:\n",
        "    return interact_roleplay([], prompt_for_roleplay)\n",
        "\n",
        "# function to call the model to generate\n",
        "def interact_roleplay(chatbot: List[Tuple[str, str]], user_input: str, temp=1.0) -> List[Tuple[str, str]]:\n",
        "    '''\n",
        "    * Arguments\n",
        "\n",
        "      - user_input: the user input of each round of conversation\n",
        "\n",
        "      - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
        "              The higher the temperature is, the more creative response you will get.\n",
        "\n",
        "    '''\n",
        "    try:\n",
        "        messages = []\n",
        "        for input_text, response_text in chatbot:\n",
        "            messages.append({'role': 'user', 'parts': [input_text]})\n",
        "            messages.append({'role': 'model', 'parts': [response_text]})\n",
        "\n",
        "        messages.append({'role': 'user', 'parts': [user_input]})\n",
        "\n",
        "        response = model.generate_content(\n",
        "          messages,\n",
        "          generation_config=genai.types.GenerationConfig(temperature=temp),\n",
        "          safety_settings=[\n",
        "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          ]\n",
        "        )\n",
        "\n",
        "        chatbot.append((user_input, response.text))\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        chatbot.append((user_input, f\"Sorry, an error occurred: {e}\"))\n",
        "    return chatbot\n",
        "\n",
        "def export_roleplay(chatbot: List[Tuple[str, str]], description: str) -> None:\n",
        "    '''\n",
        "    * Arguments\n",
        "\n",
        "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
        "\n",
        "      - description: the description of this task\n",
        "\n",
        "    '''\n",
        "    target = {\"chatbot\": chatbot, \"description\": description}\n",
        "    with open(\"part2.json\", \"w\") as file:\n",
        "        json.dump(target, file)\n",
        "\n",
        "first_dialogue = interact_roleplay([], prompt_for_roleplay)\n",
        "\n",
        "# This part constructs the Gradio UI interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(f\"# Part2: Role Play\\nThe chatbot wants to play a role game with you, try interacting with it!!\")\n",
        "    chatbot = gr.Chatbot(value = first_dialogue)\n",
        "    description_textbox = gr.Textbox(label=f\"The character the bot is playing\", interactive = False, value=f\"{character_for_chatbot}\")\n",
        "    input_textbox = gr.Textbox(label=\"Input\", value = \"\")\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Temperature\\n Temperature is used to control the output of the chatbot. The higher the temperature is, the more creative response you will get.\")\n",
        "        temperature_slider = gr.Slider(0.0, 1.0, 0.7, step = 0.1, label=\"Temperature\")\n",
        "    with gr.Row():\n",
        "        sent_button = gr.Button(value=\"Send\")\n",
        "        reset_button = gr.Button(value=\"Reset\")\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Save your Result.\\n After you get a satisfied result. Click the export button to recode it.\")\n",
        "        export_button = gr.Button(value=\"Export\")\n",
        "    sent_button.click(interact_roleplay, inputs=[chatbot, input_textbox, temperature_slider], outputs=[chatbot])\n",
        "    reset_button.click(reset, outputs=[chatbot])\n",
        "    export_button.click(export_roleplay, inputs=[chatbot, description_textbox])\n",
        "\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOoeAbW4f9XA"
      },
      "source": [
        "## Part 3: Customized Task\n",
        "In this part, you are asked to prompt your chatbot into capable of performing a certain task. You should first come up with a task you want your chatbot to perform, then prompt it into performing that task.\n",
        "\n",
        "You need to:\n",
        "1. Come up with a task and the prompt according to it. Fill the task description in **chatbot_task** and the prompt in **promot_for_task**.\n",
        "2. **Hit the run button![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==). (The run button will turn into this state![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) when sucessfully executed.)** It will pop up an interface.\n",
        "3. Interact with it for **less than 3 rounds**. Type your input in \"Input\" and hit the button \"Send\". (You can use the \"Temperature\" slide to control the creativeness of the output.)\n",
        "4. If you **want to change your prompt or the task**, hit the run button again to stop the cell. Then go back to step 1.\n",
        "5. After you get the desired result, hit the button \"Export\" to save your result. There will be a file named part3.json appears in the file list. **Remember to download it to your own computer before it disappears.**\n",
        "\n",
        "Note:\n",
        "\n",
        "\n",
        "*  If you hit the \"Export\" button again, the previous result will be covered, so make sure to download it first.\n",
        "*  chatbot task example: \"Tell me the color of the given fruit.\"\n",
        "*  prompt for task: \"Next I will tell you some fruits, and you have to telling me what color they are.\"\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Before you run this cell, make sure you have run both **Install Packages** and **Import and Setup**.\n",
        "\n",
        "**Remember to stop this cell before you go on to the next one.**\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAfCAYAAAD0ma06AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAABdaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjI5LCJ5IjowfSx7IngiOjI5LCJ5IjozMX0seyJ4IjowLCJ5IjozMX1dfRPQE4EAAAOKSURBVEhLvZbnSiRREIVrZsw5i2LAMYCKGQygPwRB//tC+zi+hYKIKAqKoCKKimLOOc/uV95uJ1xnelbwQNO5zq106vpqampC8ovwm/N/w+/3S2pqqgQCAfMkPhJ66PP5JCMjQ/Ly8qSkpEQKCwv1Oj09XT4+PuTl5UVubm7k4OBALi8v5e7uTt7e3szfsYhLyMpLS0ulsrJSysrKpKCgQMnxhoWEQiH1EEAC6e7urpyfn8vp6akuKBrfEmK4urpaOjo6pLi4WI0/PT3J9fW1evL4+Ci5ubnqMd+ygMzMTCU5PDyUtbU12d7eNta+YCVMSUmRzs5O6erqUkNnZ2duyCAkbHjJIggnXtbW1kpjY6Pk5+dLTk6OLC0tyfLycoyXMYT8PDw8LMFgUA2enJzIysqK7O3tSVNTk9TX10t5eblbJO/v73J8fCxbW1uysbEhVVVV6jXfX1xcJCYcGBiQ5uZmJcar+fl5XXF/f7+uPh7wfnZ2VvP4HSLaoqGhQerq6rRYIJuZmVFvRkdHE5IBvhkbG5OWlhbzJBYuYVpamoYxOztbXl9fNelFRUUyODhovvCOoaEhzakNLiGeUHWEklxQ1n19feZt8iA1NmgOqcT29nbp7u6W+/t7zVtWVpauNBwLCwvm6hP8Bygurnt6evTewfT0tKyurpq7T6iHqAY9RO6oyv39fa1GGxYXF92DBXBwDWk0bDaUkMbFI+cnVIMQR8PxyAbbO5uNiKKBkP7CW69i7MDmoWMrHEqIR4TT9lM4Er33AiVE8VEMKpTQopPc/xTYwFY4XMKHhwcldFoDufopbDbcHKJ7NDwFxIE22kDp2w4bbDZcLWUEjYyMqDxNTk7Kzs6OjI+Pe5I0G9DViYkJc/cF18OrqyvtQQqot7dXKioqZG5uzrxNHoi4DS4hCWZgQsx0YPA+Pz+rgCcLFOa7iRH4F7I/5loLBzL2LuxbKB4WwWzjGbmNB8I4NTUlm5ub5kksIgjx8vb2Vic+OWUPQ5sw6ZngGOQdz1iM88/R0ZG+J/d8Ew/WiU9rtLa26oRHgRB0QsReBYNEAiljmkf3WSLEEAKMQcQwbmtrc3uTvQx7GIDqsKmi19bX1607NBsiQhoOQkVvEi4nfISSoUyrkGNCzj05htwLrB5GA0L2peQVzUWQKSDEmXDTPl499EQYDsgh5AwJsohCeUXShD+F2/i/A5G/V6/Q4+FKWs8AAAAASUVORK5CYII=) means the cell is  running, ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAdCAYAAABfeMd1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHBSURBVEhL7ZUviAJREMa/uzMKgkmjRTBaFG1iNwgWk9jMgibhwKRgFgxistjsYhO02C3aNAmahTu+ZfTu7Xv770AOjvvBovvhzLc782Z8KZfLH3gyr/L5VP5NAhHIJBKJWFdQPE9XsVhEJpNBMplEKBSytNvtht1uh81mg8ViYWluOJqk02lUq1XEYjFRzJxOJ0ynU2y3W1F03lKp1Lt8f8CnbzQaCIfDojjD3+RyOVyvV+z3e1FVtJ7wDWq1mtz5hzGMNaGZsER21uu11QMvTLFEMWGZnHrQ7XYxHo9xPp9F0WEsc9hRTHiK3Fgul2g2m5jP56LomHIoJjymXvD4zmYztFotrFYrUb8w5XiYcMjuc+CH4/GI4XCIXq+n9Is57AOrNf4ZPEwul4tVCr/E43FrltrttlIi5mCu7yhv4ueYshyVSgX9fh/5fF7UL0w5FBPuIjcKhQIGgwFKpZIoOqYcigmXHXeRiU6ng3q9jmg0KooOY00LU2s8l52dbDbr63ibYolmwm06mUzkzj+McdrExi3MbXo4HJBIJDw3MUs0Go2Mg3nnd/+0TNwn2T4HXmg9cYPJgxqQQCY/5a+YAJ+sTrD9XPlWtwAAAABJRU5ErkJggg==) means the cell is idle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uAnsB6NRgLL0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "db07cd2e-33ed-4118-91e5-0d2d00fd3373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:225: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://48f283979430d195b4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://48f283979430d195b4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://48f283979430d195b4.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# TODO: Fill in the below two lines: chatbot_task and chatbot_task\n",
        "# The first is for you to tell the user that the chatbot can perform certain task\n",
        "# The second one is the prompt that make the chatbot able to do certain task\n",
        "chatbot_task = \"‰Ω†ÊòØ‰∏ÄÂêçÂ∞àÊ•≠ÁöÑÂøÉÁêÜË´ÆÂïÜÂ∏´ÔºåÁèæÂú®ÊàëÊúâ‰∏Ä‰∫õÂõ∞ÊìæÔºåË´ã‰Ω†‰ª•ÂøÉÁêÜË´ÆÂïÜÂ∏´ÁöÑË∫´‰ªΩÂõûÁ≠îÊàë‰∏ÄÊï¥ÊÆµË©±ÔºåÂÉèÊòØÂú®ÂíåÊàëËÅäÂ§©‰∏ÄÊ®£Ôºå‰∏çÁî®Êää‰Ω†ÊÄùËÄÉÁöÑÂÖßÂÆπÈ°ØÁ§∫Âá∫‰æÜ\"\n",
        "prompt_for_task = \"Ë´ã‰Ω†Ê†πÊìö‰ª•‰∏äË®≠ÂÆöÔºåÊâÆÊºîÂøÉÁêÜË´ÆÂïÜÂ∏´Ôºå‰∏¶ÊåâÁÖßÊ†ºÂºèË¶ÅÊ±ÇÂõûÁ≠îÔºå‰∏¶Á¢∫‰øùÂõûÊáâÁ¨¶Âêà‰ª•‰∏ã‰∏âÈ†ÖË¶ÅÊ±ÇÔºö1. ÂõûÁ≠îÂøÖÈ†àÊòØÂÆåÂÖ®ÁπÅÈ´î‰∏≠Êñá„ÄÇ2. ÂõûÁ≠îÁöÑÈñãÈ†≠ÂøÖÈ†àÈôÑ‰∏ä‰∏ÄÂÄãÁâπÂÆöÁöÑËÄÅÂ∏´ emojiÁ¨¶Ëôüüë©‚Äçüè´Ôºå‰∏î emoji ÁöÑ‰ΩçÁΩÆÂõ∫ÂÆöÂú®ÊúÄÈñãÈ†≠Ôºå‰∏çËÉΩÂ§öÊàñÂ∞ë„ÄÇ3. ÊØèÊ¨°ÂõûÁ≠îÁöÑÂ≠óÊï∏‰∏çÂèØ‰ª•Ë∂ÖÈÅé200 ÂÄã‰∏≠ÊñáÂ≠ó„ÄÇ\"\n",
        "\n",
        "# function to clear the conversation\n",
        "def reset() -> List:\n",
        "    return []\n",
        "\n",
        "# function to call the model to generate\n",
        "def interact_customize(chatbot: List[Tuple[str, str]], prompt: str ,user_input: str, temp = 1.0) -> List[Tuple[str, str]]:\n",
        "    '''\n",
        "    * Arguments\n",
        "\n",
        "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
        "\n",
        "      - prompt: the prompt for your desginated task\n",
        "\n",
        "      - user_input: the user input of each round of conversation\n",
        "\n",
        "      - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
        "              The higher the temperature is, the more creative response you will get.\n",
        "\n",
        "    '''\n",
        "    try:\n",
        "        messages = []\n",
        "\n",
        "        for input_text, response_text in chatbot:\n",
        "            messages.append({'role': 'user', 'parts': [input_text]})\n",
        "            messages.append({'role': 'model', 'parts': [response_text]})\n",
        "\n",
        "        messages.append({'role': 'user', 'parts': [prompt+ \"\\n\" + user_input]})\n",
        "\n",
        "        response = model.generate_content(\n",
        "          messages,\n",
        "          generation_config=genai.types.GenerationConfig(temperature=temp),\n",
        "          safety_settings=[\n",
        "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
        "          ]\n",
        "        )\n",
        "\n",
        "        chatbot.append((user_input, response.text))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        chatbot.append((user_input, f\"Sorry, an error occurred: {e}\"))\n",
        "    return chatbot\n",
        "\n",
        "def export_customized(chatbot: List[Tuple[str, str]], description: str) -> None:\n",
        "    '''\n",
        "    * Arguments\n",
        "\n",
        "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
        "\n",
        "      - description: the description of this task\n",
        "\n",
        "    '''\n",
        "    target = {\"chatbot\": chatbot, \"description\": description}\n",
        "    with open(\"part3.json\", \"w\") as file:\n",
        "        json.dump(target, file)\n",
        "\n",
        "# this part is to construct the Gradio UI interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Part3: Customized task\\nThe chatbot is able to perform a certain task. Try to interact with it!!\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    desc_textbox = gr.Textbox(label=\"Description of the task\", value=chatbot_task, interactive=False)\n",
        "    prompt_textbox = gr.Textbox(label=\"Prompt\", value=prompt_for_task, visible=False)\n",
        "    input_textbox = gr.Textbox(label=\"Input\")\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Temperature\\n Temperature is used to control the output of the chatbot. The higher the temperature is, the more creative response you will get.\")\n",
        "        temperature_slider = gr.Slider(0.0, 1.0, 0.7, step = 0.1, label=\"Temperature\")\n",
        "    with gr.Row():\n",
        "        sent_button = gr.Button(value=\"Send\")\n",
        "        reset_button = gr.Button(value=\"Reset\")\n",
        "    with gr.Column():\n",
        "        gr.Markdown(\"#  Save your Result.\\n After you get a satisfied result. Click the export button to recode it.\")\n",
        "        export_button = gr.Button(value=\"Export\")\n",
        "    sent_button.click(interact_customize, inputs=[chatbot, prompt_textbox, input_textbox, temperature_slider], outputs=[chatbot])\n",
        "    reset_button.click(reset, outputs=[chatbot])\n",
        "    export_button.click(export_customized, inputs=[chatbot, desc_textbox])\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yAsaWKvAPPfZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Xuh2R5DQSrcO"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}